Chapter 2 85 2. Run the code and view the result, as shown in the following output: Using doubles: 0.1 + 0.2 does NOT equal 0.3 In cultures that use a comma for the decimal separator, the result will look slightly different, as shown in the following output: 0,1 + 0,2 does NOT equal 0,3. The double type is not guaranteed to be accurate because most numbers like 0.1, 0.2, and 0.3 literally cannot be exactly represented as floating-point values. If you were to try different values, like 0.1 + 0.3 == 0.4, it would happen to return true because with double values, some imprecise values happen to be exactly equal in their current representa- tion even though they might not actually be equal mathematically. So, some numbers can be directly 0.1 and 0.2 to compare to 0.3 because they cannot compared but some cannot. I deliberately picked be compared, as proven by the result. You could compare real numbers stored in the float type, which is less accurate than the double type, but the comparison would actually appear to be true because of that lower accuracy! float a = 0.1F; float b = 0.2F; if (a + b == 0.3F) // True because float is less "accurate" than double. ... As a rule of thumb, you should only use double when accuracy, especially when comparing the equal- ity of two numbers, is not important. An example of this might be when you’re measuring a person’s height; you will only compare values using greater than or less than, but never equals. The problem with the preceding code is illustrated by how the computer stores the number 0.1, or multiples of it. To represent 0.1 in binary, the computer stores 1 in the 1/16 column, 1 in the 1/32 column, 1 in the 1/256 column, 1 in the 1/512 column, and so on. The number 0.1 in decimal is 0.00011001100110011… in binary, repeating forever: Figure 2.7: Number 0.1 in decimal repeating forever in binary 